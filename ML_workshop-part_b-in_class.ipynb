{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# __Machine Learning Workshop Part-B__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ___Learning objectives___\n",
    "\n",
    "At the end of the exercise, you should be able to:\n",
    "- Conduct an end-to-end classification analysis given data\n",
    "- Interpret model with example global and local interpretaion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing first: test your install\n",
    "import sklearn, pandas, matplotlib, seaborn, imblearn, numpy, shap, tqdm\n",
    "\n",
    "# If you encounter error, talk to the instructors and/or your neighbor ASAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Outline___\n",
    "\n",
    "- Session 1\n",
    "  - Intro to machine learning\n",
    "  - [Part A review](#review)\n",
    "  - [Step 1. Define ML problem](#step1)\n",
    "  - [Step 2. Exploratory data analysis](#step2)\n",
    "  - [Step 3: Split train/test](#step3)\n",
    "- Session 2\n",
    "  - [Step 4: Feature engineering](#step4)\n",
    "  - [Step 5: Select model](#step5)\n",
    "  - [Step 6: Repeat 2-5](#step6)\n",
    "- Session 3\n",
    "  - [Step 7: Evalute model](#step7)\n",
    "  - [Step 8: Interpret model](#step8)\n",
    "  - Workshop wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "<a id=\"review\"></a>\n",
    "\n",
    "## ___Part A review___\n",
    "\n",
    "&#9989; <font color=red>**QUESTION:**</font> In __Part A__, we have gone thorugh the major steps. __In the next 5 minutes__, discuss with your neighbors: What is your understanding of each step? Is there any step or term that is confusng to you? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a id=\"step1\"></a>\n",
    "## ___Step 1. Define ML problem___\n",
    "\n",
    "___Problem statement___: \n",
    "- Given:\n",
    "  - Known genes in general metabolism (GM) or specialized metabolism (SM)\n",
    "  - Various features of genes\n",
    "    - E.g., expression levels, functional category they belong to \n",
    "- How can we use them to:\n",
    "  - Distinguish genes involved in GM from those involved in SM?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; <font color=red>**QUESTION:**</font> __In the next two minutes__, discuss with your neighbors: what features should we use to best distinguish GM and SM genes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"step2\"></a>\n",
    "## __Step 2. Exploratory data analysis (EDA)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Run the following cell to load the data. Note that we set a random seed (`rand_seed`). This is so we can reprdouce the random data generated along the way so others can repeat the same analysis and get the similar, if not the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rand_seed = 20240507\n",
    "\n",
    "# Load the dataset from the file enzyme_gene.csv as a Pandas DataFrame where the\n",
    "# `Gene` column is read in as index.\n",
    "enzyme_gene = pd.read_csv(\"enzyme_gene.csv\", index_col=0)\n",
    "\n",
    "# get all feature names\n",
    "features = enzyme_gene.columns[1:] \n",
    "\n",
    "# get all feature names\n",
    "# Print out 4 randomly sampled instances\n",
    "enzyme_gene.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** __In the next minute__, discuss with your neighbors: which features do you think will be the best for distinguishing GM and SM genes? For what the feature names mean, see [this spreadsheet](https://docs.google.com/spreadsheets/d/1VjnlJgKsGC8GNNds7VtbYfjAQpjETkZNI6AlF9c2DAY/edit?usp=sharing). Also, put your name down for the feature you think will be the best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___2.1 Univariate EDA___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Earlier, we use `enzyme_gene.sample(4)` to get a few samples from the `enzyme_gene` dataframe. Replace `sample(4)` with `describe()` and see what information become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "# If you are not sure how to proceed, look at the answer in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ANSWER##\n",
    "# Generate summary statics for each features\n",
    "enzyme_gene.describe()\n",
    "##ANSWER##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Tell us more about `enzyme_gene` by using `shape` and `nunique()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your codes here\n",
    "\n",
    "# Display the # of columns and rows\n",
    "print(\"\\nShape:\", enzyme_gene.shape)\n",
    "\n",
    "# Display the # of unique values in each feature\n",
    "print(\"\\n### Number unique:\\n\", enzyme_gene.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Run the following to determine how many entires have `GM`, `SM`, and `Unknown` labels, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enzyme_gene[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Determine the number of `null` entries in each column and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_gene.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___2.2 Univariate graphical EDA___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Plot the histograms of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1st \":\" is to get all rows. The \"1:\" part is to get the 2nd column and on.\n",
    "feature_values = enzyme_gene.iloc[:, 1:]\n",
    "\n",
    "# Draw histogram\n",
    "hist = feature_values.hist(figsize=(12,12), bins=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  __In the next 1 minute__, discuss with your neighbors: did you see any issues with the dataset based on the above analyses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___2.3 Multi-variate non-graphical EDA___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Determine pairwise Spearman's rank correlations of all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Spearman's rank correlations for all feature pairs\n",
    "corr = feature_values.corr(method = 'spearman')\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___2.4 Multi-variate graphical EDA___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Plot the pairwise Spearman's rank correlations of all features as a heatmap using Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  __In the next 1 minute__, discuss with your neighbors: did you see any issues with the dataset based on the univariate analyses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"step3\"></a>\n",
    "## __Step 3: Split train/test__\n",
    "\n",
    "The best practice is alway to set aside testing data __as the FIRST STEP__ or as early as possible. This way, the testing data is truly independent from any of the modeling process aside from the processing steps needed. Nonetheless, there may be things you need to take care of first before splitting the data. In this example, we need to rid of unwanted instances before data split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ___3.1 Deal with unwanted instances___\n",
    "\n",
    "&#9989; **<font color=blue>DO THIS:</font>** Filter data so only instances with `SM` and `GM` labels are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels              = ['GM', 'SM']\n",
    "label_column        = enzyme_gene['Label']\n",
    "label_column_filter = label_column.isin(labels)\n",
    "\n",
    "# enzyme_gene dataframe with only GM and SM\n",
    "enzyme_gene_fil = enzyme_gene[label_column_filter]\n",
    "\n",
    "# Count the occurence of unique values\n",
    "enzyme_gene_fil['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** For classification tasks, class values are typically integers instead of texts (like SM or GM here). So, we will convert `GM` and `SM` to 0 and 1, respectively. \n",
    "\n",
    "Write code at the end to show that the filtering is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the proprecessing functions\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Create a LabelEncoder object: this is simply a software tool that turn \n",
    "# (encode) texts into 0 or 1 (labels) in this case.\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Send the Label column of enzyme_gene_fil dataframe to the LabelEncoder so\n",
    "# it can fit (i.e., learn) how to encode the labels.\n",
    "le.fit(enzyme_gene_fil.Label)\n",
    "\n",
    "# Now, used the fitted (learned) encoder to transform texts to labels\n",
    "enzyme_gene_fil['Label'] = le.transform(enzyme_gene_fil.Label)\n",
    "\n",
    "# Write code below to show that the Label encoding is working: 0s and 1s\n",
    "\n",
    "\n",
    "# If you are not sure how to proceed, look at the answer in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ANSWER##\n",
    "enzyme_gene_fil['Label'].value_counts()\n",
    "##ANSWER##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___3.2 Split training/testing sets___\n",
    "\n",
    "&#9989; **<font color=blue>DO THIS:</font>** Let's split the training and testing data. \n",
    "\n",
    "Please comments on the lines as indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "train, test = train_test_split(\n",
    "                enzyme_gene_fil,                # The data to split\n",
    "                test_size=0.2,                  # Proportion data for testing\n",
    "                stratify=enzyme_gene_fil.Label, # Make sure proportions of 0/1\n",
    "                                                # labels are similar between\n",
    "                                                # training and testing sets\n",
    "                random_state=rand_seed)\n",
    "\n",
    "# Print out proportions of different labels in the training data\n",
    "print(train['Label'].value_counts()/train.shape[0])\n",
    "\n",
    "# Print out proportions of different labels in the testing data\n",
    "print(test['Label'].value_counts()/test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  In __the next 2 minutes__, discuss with your neighbor: what's the point of splitting training and testing data again? How big should the testing data be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"step4\"></a>\n",
    "## __Step 4: Feature engineering__\n",
    "\n",
    "Feature engineering involves processing, transforming, selecting, combining features in ways that will improve the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___4.1 Deal with missing data___\n",
    "\n",
    "We will just try to deal with this in one way. __In reality__, You need to try multiple approaches to see how you can get the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** First let's remind ourself how many instances are there after we get rid of `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_gene_fil.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Let's drop any rows with >25% missing values and see how many instances are still there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask which values are null.\n",
    "row_na     = enzyme_gene_fil.isnull()\n",
    "row_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the mising values (null, NA, or called NaN: Not a Number) of each crow\n",
    "row_na_num = train.isnull().sum(axis=1)\n",
    "row_na_num[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat     = train.shape[1] - 1            # number of features in the data\n",
    "rows_to_keep = row_na_num/num_feat < 0.25    # rows with <25% missing values\n",
    "train_keep = train[rows_to_keep]             # training data with rows to keep \n",
    "train_keep['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** A lot of data is removed but this is much better than just drop any row with missing values. Next, let's try to impute the missing values with `KNNImputer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create an imputer object to imptue our data\n",
    "# n_neighbors is the number of neighbors used to estimate the missing values.\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Train the imputer with training data\n",
    "imputer.fit(train_keep)\n",
    "\n",
    "# Transform missing values into imputed values, hence train_keep_imp (imputed)\n",
    "train_keep_imp = imputer.transform(train_keep)\n",
    "\n",
    "# The thing with KNNImputer is it create train_keep_imp as a Numpy array so\n",
    "# we don't have the column names any more. Because I really want to know what \n",
    "# these columns are, so let's turn this back to a DataFrame with column names.\n",
    "train_keep_imp = pd.DataFrame(train_keep_imp, columns=train.columns)\n",
    "train_keep_imp.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=orange>CAUTION:</font>** There is a hyperparamter here: `n_neighbors`. We set it to 5 here but __in reality__, multiple values need to be evaluated. Also, you DO NOT impute labels. We did not exclude the label column because we have make sure there is no missing value early on. So imputation will not impact it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Follow what we have done for the training data. Write code that will impute the testing set:\n",
    "1. Drop any rows with > 25% missing values.\n",
    "2. Impute missing value with KNNImputer.\n",
    "3. Check that there is no missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "\n",
    "# I encourage you to try to figure this out. If you get stuck. Look at the \n",
    "# answer below and comments on what each line does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ANSWER##\n",
    "# Sum the number of NAs in each row of the testing set\n",
    "row_na_num = test.isnull().sum(axis=1)\n",
    "\n",
    "# Get the number of features\n",
    "num_feat   = test.shape[1] - 1\n",
    "\n",
    "# Determine which rows have below threshold (25%) NAs\n",
    "row_na_below_threshold = row_na_num/num_feat < 0.25\n",
    "\n",
    "# Get the rows we want to keep\n",
    "test_keep  = test[row_na_below_threshold]\n",
    "\n",
    "# Impute missing values\n",
    "test_keep_imp = imputer.transform(test_keep)\n",
    "test_keep_imp = pd.DataFrame(test_keep_imp, columns=test.columns)\n",
    "test_keep_imp.isnull().sum()\n",
    "##ANSWER##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  In __the next 2 minutes__, discuss with your neighbor: note that here `testing` data is not used to `fit` the imputer. Instead, the imputer fitted with training data is used to `tranform` test set. Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: when you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___4.2 Deal with data imbalance___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Here we will use a hybrid approach:\n",
    "- Up-sample the minority class so it has twice as many instances __AND__ \n",
    "- Downsample the majority class so it is the same number as the minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keep_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# training features\n",
    "X_train = train_keep_imp.iloc[:,1:] \n",
    "\n",
    "# training labels\n",
    "y_train = train_keep_imp.iloc[:,0]  \n",
    "\n",
    "# This will be used in many other occasions.\n",
    "feat_names = X_train.columns \n",
    "\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(\"Before:\", counter)\n",
    "\n",
    "# Over-sample minority, under-sample majority\n",
    "over = SMOTE(sampling_strategy=0.4)\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_train_bal, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train)\n",
    "print(\"After :\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** In __the next 2 minutes__, discuss with your neighbor: Resampling, particularly upsampling can __only__ be applied to the training data. The testing set __should not__ be changed in this step. Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___4.3. Deal with data scaling___\n",
    "\n",
    "&#9989; **<font color=blue>DO THIS:</font>** Bassed on your exploratory data analsysi you probably the data range differ widely. Before we work on scaling the data, let's see how the data ranges differ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>**  In the cell below, let's use `RobustScaler` to scale the balanced training data feature values (`X_train_bal`).\n",
    "\n",
    "__DO NOT__ applying scaling to the labels (`y`).\n",
    "\n",
    "Call the scaled features as `X_train_scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# initialize a scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# fit the scaler with training features\n",
    "scaler.fit(X_train_bal)\n",
    "\n",
    "# transform the training feature values with the fitted scaler\n",
    "X_train_scale = scaler.transform(X_train_bal)\n",
    "X_train_scale = pd.DataFrame(X_train_scale, columns=X_train.columns)\n",
    "X_train_scale.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Provide code below to process testing data so it is scaled the same way.\n",
    "- Create `X_test` and `y_test` with `test_keep_imp`.\n",
    "- Transform (but __do not__ fit) `X_test` with the `RobustScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "\n",
    "# If you don't feel comfortable doing this, check out the answer below and\n",
    "# comment on what they are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "##ANSWER##\n",
    "X_test = test_keep_imp.iloc[:,1:]\n",
    "y_test = test_keep_imp.iloc[:,0]\n",
    "\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "X_test_scale = pd.DataFrame(X_test_scale, columns=X_test.columns)\n",
    "##ANSWER##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=orange>CAUTION:</font>** We __did not__ deal with non-normal distributions or co-linear features. In practice, they need to be dealth with. To make the exercise simpler, we did not include categorical variable. For starter, please checkout, after class:\n",
    "- [This post on data transformation](https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/).\n",
    "- [This post on colinearity](https://towardsdatascience.com/multicollinearity-in-data-science-c5f6c0fe6edf).\n",
    "- [This post on how to work with categorical variables](https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/).\n",
    "- More generally, [here is a good article on feature engineering](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"step5\"></a>\n",
    "## __Step 5: Select model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___5.1 Random forest___\n",
    "\n",
    "&#9989; **<font color=blue>DO THIS:</font>** Here we will not go into details on how the RandomForest algorithm works. there is a substantial number of good tutorial/blog posts on RandomForest (e.g., [this one](https://machinelearningmastery.com/bagging-and-random-forest-ensemble-algorithms-for-machine-learning/)) and I encourage you to look into it. Comments on the major steps as indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a function for running RandomForest\n",
    "def run_randomforest(X_train, y_train):\n",
    "    # Below is a Python dictionary specify the hyperparameters to be tested\n",
    "    #  2x3x4x1 = 24\n",
    "    param_grid = {'n_estimators': [200, 500],\n",
    "                  'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                  'max_depth' : [3,5,7,9],\n",
    "                  'criterion' :['entropy']}\n",
    "\n",
    "    # Initialize a random forest classifier (rfc) with a random seed\n",
    "    rfc = RandomForestClassifier(random_state=rand_seed)\n",
    "\n",
    "    # Initialize a grid search object that will search through each of the 24\n",
    "    # hyperparameter combinations. For each combination, a five fold cross-\n",
    "    # validation (cv) is done. So totally 24x5 = 120 random forest classifiers \n",
    "    # will be build.\n",
    "    rfc_gs = GridSearchCV(\n",
    "                rfc,\n",
    "                param_grid,\n",
    "                cv=5,              # cross validation folds\n",
    "                verbose=2,         # \n",
    "                scoring='roc_auc', # find model with the best ROC-AUC\n",
    "                n_jobs=8)          # number of concurrent jobs, you need to\n",
    "                                   # adjust this based on the number of CPU cores\n",
    "                                   # available on your machine.\n",
    "\n",
    "    # Pass the training feaure and label data to the grid search object and\n",
    "    # start fitting (training) models\n",
    "    rfc_gs.fit(X_train, y_train)\n",
    "\n",
    "    # Return the fitted grid search object\n",
    "    return rfc_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the run_randomforest function defined above\n",
    "rfc_gs = run_randomforest(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** In the `grid_search` object, there is whole punch of useful information. Run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model (also called estimator)\n",
    "best_model = rfc_gs.best_estimator_\n",
    "\n",
    "# Note that the best hyperparameters are also reported\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best ROC-AUC score averged across CV folds for the best model\n",
    "print(rfc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Although we finished the run rather quickly here, a typical model fitting process can take hours or even days! Thus, the models should be saved so you can reused them in the future. Run the following to save the best estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"model_randomforest_gridsearch.save\"\n",
    "\n",
    "pickle.dump(rfc_gs.best_estimator_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** In __the next 2 min__, discuss with your neighbors: what just happened here? Can you describe what you have accomplished in this step and what are done? Discuss with your neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___5.2 Support Vector Classifier (SVC)___\n",
    "\n",
    "&#9989; **<font color=blue>DO THIS:</font>** There are [many other supervised learning algorithms in Scikit-Learn](https://scikit-learn.org/stable/supervised_learning.html). Let's use [Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC). \n",
    "\n",
    "Provide comment on the indicated lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVM classification model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# COMMENT: What does this do?\n",
    "#\n",
    "param_grid = {'C': [1, 10, 1e2],\n",
    "              'gamma': [0.0001, 0.001, 0.01, 0.1], \n",
    "              'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# COMMENT: What does this do?\n",
    "# \n",
    "svc    = SVC()\n",
    "\n",
    "# COMMENT: What does this do?\n",
    "# \n",
    "svc_gs = GridSearchCV(svc, param_grid, cv=5, verbose=2, scoring='roc_auc',\n",
    "                      n_jobs=8)\n",
    "\n",
    "# COMMENT: What does this do?\n",
    "# \n",
    "svc_gs.fit(X_train_scale, y_train)\n",
    "\n",
    "# COMMENT: What does this do?\n",
    "# \n",
    "filename = \"model_svc_gridsearch.save\"\n",
    "pickle.dump(svc_gs.best_estimator_, open(filename, 'wb'))\n",
    "\n",
    "# COMMENT: What does these do?\n",
    "# \n",
    "print(svc_gs.best_params_)\n",
    "print(svc_gs.best_score_)\n",
    "\n",
    "##COMMENT ANSWERS##\n",
    "#  Set up the hyperparameter combinations: 3x4x2 = 24 runs\n",
    "#  Intialize a support vector classifier\n",
    "#  Initiate a grid search object with cross validation\n",
    "#  Search for the best hyperparameters with training data\n",
    "#  Save the best model as a file\n",
    "#  Print out the best parameters and best scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=orange>CAUTION:</font>** We just try two algorithms here, you should try a lot more.\n",
    "\n",
    "In addition, beyond the hyperparameters associated with the algorithms, there are other things to tuned here:\n",
    "- Cross validation methods: There are quite a number of approaches. See [this](https://scikit-learn.org/stable/modules/cross_validation.html) for examples.\n",
    "- Searching parameters: Grid search is but one approach. Two other popular methods are [randomized search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) and [Bayesian optimization](https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html). These should also be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** In __the next 2 min__, discuss with your neighbors: based on the above two runs, can you decide which algorithm is better? Why and why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"step6\"></a>\n",
    "## __Step 6. Repeat Step 2-5__\n",
    "\n",
    "In a typical ML project, after you have explored different algorithms to find the best __initial__ model, it is time to go back to tweak everything to see if you can do even better. Things don't just end here!\n",
    "\n",
    "An important step here is __feature selection__, a part of feature engineering, that involves selecting the most important features to rebuild your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ___6.1 Get feature importance using trained model___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>**  Uses the feature importance scores generated by the Random Forest model to choose the top features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Specify the best model (estimator) from our RandomForest run\n",
    "rfc = rfc_gs.best_estimator_\n",
    "\n",
    "# Calculate permutation importance of each feature\n",
    "result = permutation_importance(\n",
    "    rfc, X_train_scale, y_train, n_repeats=10, random_state=42, n_jobs=8)\n",
    "\n",
    "# COMMENTS: What can you find in the result?\n",
    "#\n",
    "#\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##COMMENT ANSWER##\n",
    "# importance_mean: mean importance value of each feature\n",
    "# importance_std: imporrtance standard deviation of each feature\n",
    "# importance: the importance scores of each feature for each repeat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the permutation importance based on mean values\n",
    "sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the importance values in order of the sorted_idx\n",
    "importance_values = result.importances[sorted_idx].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names based on the sorted index\n",
    "ordered_feature_label = X_train_scale.columns[sorted_idx]\n",
    "ordered_feature_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the permutation importance results\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.boxplot(importance_values, \n",
    "           vert=False, \n",
    "           labels=ordered_feature_label)\n",
    "ax.set_title(\"Permutation Importances (training set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** In __the next 2 min__, discuss with your neighbors: how would you interpret the figure above? Is this as what you have expected when you hypothesize the most important feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ___6.2 Retrain model using top 10 features___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>**  A simpler model is always better, because it is easier to understand and because it tends not to be overfitted. Let's use the top 10 features to train a new RandomForest model and see how well it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get top 10 feature names\n",
    "feat_top10 = ordered_feature_label[:10]\n",
    "\n",
    "# Get training data with only the top 10 features\n",
    "X_train_top10 = X_train_scale[feat_top10]\n",
    "X_train_top10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Do the same for testing data\n",
    "X_test_top10 = X_test_scale[feat_top10]\n",
    "X_test_top10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Train RandomForest model via grid search\n",
    "rfc_gs_top10 = run_randomforest(X_train_top10, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "filename = \"model_randomforest_gridsearch_top10feat.save\"\n",
    "\n",
    "pickle.dump(rfc_gs_top10.best_estimator_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model score\n",
    "rfc_gs_top10.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** In __the next 2 min__, discuss with your neighbors: compare this result to the model with all features, should we just use the top 10? Why and why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"step7\"></a>\n",
    "## __Step 7. Evaluate model with the testing set__\n",
    "\n",
    "Assume that we are done with model building and have a final model that we cannot improve further. Then it is time to use the testing set to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___7.1 Using the optimal model to predict testing set___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Random Forest is a little better than SVC. And because using 10 features leads to a model that perofrm almost as well as the one with more features, we will pick the \"optimal\" model to be the random forest model using only 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = \"model_randomforest_gridsearch_top10feat.save\"\n",
    "\n",
    "# load model from file\n",
    "rfc_loaded_top10 = pickle.load(open(filename2, 'rb')) # model using top 10\n",
    "\n",
    "# predict testing data labels with the model using top 10 features\n",
    "y_test_pred = rfc_loaded_top10.predict(X_test_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the 1st 40 predictions\n",
    "print(y_test_pred[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also take a look at the 1st 40 TRUE values\n",
    "print(numpy.array(y_test[:40]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "&#9989; <font color=red>**QUESTION:**</font> Based on the above results? Do you feel that the model is doing well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___7.2 Confusion matrix___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Let's generate __confusion matrices__ for the predicted results from the model with all features and the one with just the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Get confusion matrrix\n",
    "cm_top10 = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(cm_top10).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix on the left tell us that:\n",
    "- Number of true negative ($tn$) = 292\n",
    "- Number of false positive ($fp$) = 75\n",
    "- Number of false negative ($fn$) = 17\n",
    "- Number of true positive ($tp$) = 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "&#9989; <font color=red>**QUESTION:**</font> In __the next 1 min__, discuss with your neighbors: based on the above results? Do you feel that the model is doing well? Why and why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___7.3 Classification report___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=orange>CAUTION:</font>** The metrics printed out are defined below. Unfortunately, we __do not have time__ to go through these. But for you to run an ML project, these, including ROC-AUC, are __foundational knowledge and you need to know the advantage and disadvantage of using them__. [Here is an excellent summary](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/) of important metrics for evaluating ML models.\n",
    "\n",
    "|Metric|Formula|\n",
    "|---|---|\n",
    "|Precision|$p = tp/(tp + fp)$|\n",
    "|Recall|$r = tp / (tp + fn)$|\n",
    "|F1 score|$f1 = 2(p\\times r)/(p + r)$|\n",
    "|Accuracy|$(tp+tn)/(tp+fp)$|\n",
    "|Macro averge|$0.5\\times score_{\\text{class0}} + 0.5\\times score_{\\text{class1}}$|\n",
    "|Weighted averge|$P_{\\text{class0}}\\times score_{\\text{class0}} + P_{\\text{class1}}\\times score_{\\text{class1}}$<br>$P$: proportion of a class.|\n",
    "\n",
    "Support: number of each class (not a performance metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Let's also generate a classification report to get a few other performance matrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set class names\n",
    "targets = [\"GM\", \"SM\"]\n",
    "\n",
    "report = classification_report(y_test, y_test_pred, target_names=targets)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: once you finish, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___7.4 Graphics that help with evaluation___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Here we provide two examples: ROC-AUC curve and precision-recall curve. The red dotted line indicate how a naive classifer woul fair with __random guesses__. We only plot these curves for the model with top 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "def plot_curves(X, y, estimator, background):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "    # ROC-AUC curve\n",
    "    RocCurveDisplay.from_estimator(estimator, X, y, ax=axs[0])\n",
    "    # Plot ROC-AUC background\n",
    "    axs[0].plot([0, 1], [0, 1],'r--')\n",
    "\n",
    "    # Precision-recall curve\n",
    "    PrecisionRecallDisplay.from_estimator(estimator, X, y, ax=axs[1])\n",
    "    axs[1].legend(loc='upper right')\n",
    "    # Plot PR-curve background\n",
    "    axs[1].plot([0, 1], [background, background],'r--')\n",
    "    axs[1].set_ylim(-0.05,1.05)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "num_class0 = y_test[y_test==0].shape[0]\n",
    "num_class1 = y_test[y_test==1].shape[0]\n",
    "background = num_class1/(num_class0+num_class1)\n",
    "print(background)\n",
    "\n",
    "plot_curves(X_test_top10, y_test, rfc_loaded_top10, background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "&#9989; <font color=red>**QUESTION:**</font> The red lines are what we expect a random model will be performing. For the plot on the right-hand side, it is defined by the `background` value defined in the cell above. Why would it be cosndiered as `background` (i.e., random guess) for the right-hand plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Let's also get these curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class0 = y_train[y_train==0].shape[0]\n",
    "num_class1 = y_train[y_train==1].shape[0]\n",
    "background = num_class1/(num_class0+num_class1)\n",
    "print(background)\n",
    "\n",
    "plot_curves(X_train_top10, y_train, rfc_loaded_top10, background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "&#9989; <font color=red>**QUESTION:**</font> In __the next 2 min__, discuss with your neighbor: why are the model performance for training data so much better than that for the testing set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: after your discussion, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"step7\"></a>\n",
    "## __Step 8. Interpret model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___8.1 Global interpetation using SHAP___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Run the code below to get [SHAP (SHapley Additive exPlanations)](https://shap.readthedocs.io/en/latest/index.html) values that use game theory to determine how important each feature is in contributing to a prediction. There are MANY, MANY things you can do with SHAP and we will first figure out which features are more important than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Get a TreeExplainer object using the model we have created\n",
    "explainer = shap.TreeExplainer(rfc_loaded_top10)\n",
    "\n",
    "# Use the TreeExplainer to get SHAP values for the training data\n",
    "shap_values = explainer.shap_values(X_train_top10)\n",
    "\n",
    "# Generate a summary plot\n",
    "shap.summary_plot(shap_values, X_train_top10, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `Fam_size` is the most important. Because we have only two classes, if a feature is important for classifyting one class, it must also be important for the other class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___8.2 SHAP values of different instances___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Another way to look at the SHAP values is by focusing on a particular class. In the example below, we focus on how different features contribute to the predictions of label=1 (SM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_for_label1 = shap_values[1]\n",
    "\n",
    "# plot the shape value and color based on feature values\n",
    "shap.summary_plot(shap_for_label1, X_train_top10, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each feature $x$, two SHAP values are generated for each instance: one for $x$'s contribution to class $0$ and the other for its contribution to class $1$. In the plot above, we are only looking at the contribution to class $1$ and each dot is an instance.\n",
    "\n",
    "Look at Fam_size (family size), instances with higher features values (i.e., in larger families) also tend to have higher positive SHAP values (i.e., positive contribution to be in class 1).\n",
    "\n",
    "&#9989; <font color=red>**QUESTION:**</font> In __the next 2 min__, discuss with your neighbor and interpret what the `Func_likelihood` feature's SHAP value distribution means where a higher feature values correlate with lower SHAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: after your discussion, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('bert_finetune': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "323c618d0395b34183a36199d7c8eddbd4e55d51aee9dabbfbc9809db817fb2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
