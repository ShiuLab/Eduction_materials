{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# __Part-c: eXplainable AI/ML (XAI)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Learning objectives\n",
    "\n",
    "At the end of the exercise, you should be able to:\n",
    "- Explain why it is important to explain your model.\n",
    "- Interpret model with example global and local interpretaion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing first: test your install\n",
    "import sklearn, pandas, matplotlib, seaborn, imblearn, numpy, shap, tqdm\n",
    "\n",
    "# If you encounter error, talk to the instructors and/or your neighbor ASAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [5 min] Intro (powerpoint)\n",
    "- [[10 min] Background](#background)\n",
    "- [[05 min] Step 8: Interpret model](#step7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "<a name=\"background\"></a>\n",
    "\n",
    "# __Background__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"workflow\"></a>\n",
    "## _Machine learning workflow_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Step|Purpose|Notes|\n",
    "|---|---|---|\n",
    "|1|State the question and frame it as a machine learning problem|Is it a supervised or unsupervised learning problem? There are other major types (semi-supervised and reinforced learning).|\n",
    "|2|Collect data, and exploratory data analysis (EDA)|Apply four types of EDA.|\n",
    "|3|Split training and testing data|Seperate out testing data for evaluation purpose.|\n",
    "|4|Engineer features| - Format data, impute missing values, normalize/scale features.<br>- Transform feature values, select informative features,<br>- Create combinatorial features (e.g., the interaction terms for basic linear model).<br>- Do dimension reduction to reduce the number of features.|\n",
    "|5|Select models| - There are many models/algorithms/classifers making different assumptions about how modeling should be done. Thus, it is important to go through a wide range of them.<br>- And for each model/algorith, we need to tune __hyperparameters__, i.e., parameters that are set manually.<br>- Cross-validate model, i.e., separate data into training/validation subsets, use the training subset to train a model and score the model with the validation subset. Then split the training/validation subset again but differently, train and score. Repeat the process $k$ times.|\n",
    "|6|Repeat 2-5|Work to iteratively improve the models.|\n",
    "|7|Evaluate the best performing model|- After a best performing model is identified based on the training data, the model is applied to the testing set.<br>- Various model performance metric can be used to access how good the model is.|\n",
    "|8|Interpret the model|- Dissect the model to better understand how it works.<br>- Identify most informative features for the best performing model.<br>- Assess the reasons behind false predictions to further improve model.|\n",
    "|9|Deploy model|Apply model to new data and make predictions.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _What is interpretability_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Why interpret the model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blah blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"step1\"></a>\n",
    "# __Step 1. Define ML problem__\n",
    "\n",
    "___Problem statement___: \n",
    "- Following this published paper:\n",
    "  - [Robust predictions of specialized metabolism genes through machine learning](https://www.pnas.org/doi/abs/10.1073/pnas.1817074116)\n",
    "- Given:\n",
    "  - Known genes in general metabolism (GM) or specialized metabolism (SM)\n",
    "  - Various features of genes\n",
    "    - E.g., expression levels, functional category they belong to \n",
    "- How can we use them to:\n",
    "  - Distinguish genes involved in GM from those involved in SM?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"step2\"></a>\n",
    "## __Step 2-7. From exploratory data analysis to model evaluation__\n",
    "\n",
    "We will skip all these steps to cut to the chase. Here we will use a model that has already been build for model interpretation. If you'd like to learn more about how the model was built, see [our ML workshop](https://github.com/ShiuLab/ML_workshop) materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Run the following cell to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"step7\"></a>\n",
    "## __Step 8. Interpret model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___8.1 Global interpetation using SHAP___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Run the code below to get [SHAP (SHapley Additive exPlanations)](https://shap.readthedocs.io/en/latest/index.html) values that use game theory to determine how important each feature is in contributing to a prediction. There are MANY, MANY things you can do with SHAP and we will first figure out which features are more important than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Get a TreeExplainer object using the model we have created\n",
    "explainer = shap.TreeExplainer(rfc_loaded_top10)\n",
    "\n",
    "# Use the TreeExplainer to get SHAP values for the training data\n",
    "shap_values = explainer.shap_values(X_train_top10)\n",
    "\n",
    "# Generate a summary plot\n",
    "shap.summary_plot(shap_values, X_train_top10, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `Fam_size` is the most important. Because we have only two classes, if a feature is important for classifyting one class, it must also be important for the other class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___8.2 SHAP values of different instances___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=blue>DO THIS:</font>** Another way to look at the SHAP values is by focusing on a particular class. In the example below, we focus on how different features contribute to the predictions of label=1 (SM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_for_label1 = shap_values[1]\n",
    "\n",
    "# plot the shape value and color based on feature values\n",
    "shap.summary_plot(shap_for_label1, X_train_top10, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each feature $x$, two SHAP values are generated for each instance: one for $x$'s contribution to class $0$ and the other for its contribution to class $1$. In the plot above, we are only looking at the contribution to class $1$ and each dot is an instance.\n",
    "\n",
    "Look at Fam_size (family size), instances with higher features values (i.e., in larger families) also tend to have higher positive SHAP values (i.e., positive contribution to be in class 1).\n",
    "\n",
    "&#9989; <font color=red>**QUESTION:**</font> In __the next 2 min__, discuss with your neighbor and interpret what the `Func_likelihood` feature's SHAP value distribution means where a higher feature values correlate with lower SHAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9978; **<font color=purple>PAUSE: after your discussion, please turn your attention to the instructor. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, we're done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('sklearn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b31353e0b5417ab1909bc62ced18dcd0f4fa5d6ceab54c18c132f16ad2bde54b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
